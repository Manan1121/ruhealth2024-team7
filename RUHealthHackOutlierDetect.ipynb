{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1e7MRq-m4OKC1ig_H-MJ9ontiTID7myR9",
      "authorship_tag": "ABX9TyOGqzZ7JPUYU6Ocfw3MG440",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joelkny97/ruhealth2024-team7/blob/develop/RUHealthHackOutlierDetect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "YxFKBqCu5eoH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beneficiary_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/RUHealthHack/DE1_0_2008_Beneficiary_Summary_File_Sample_1.csv\")\n",
        "inpatient_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/RUHealthHack/DE1_0_2008_to_2010_Inpatient_Claims_Sample_1.csv\")\n",
        "outpatient_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/RUHealthHack/DE1_0_2008_to_2010_Outpatient_Claims_Sample_1.csv\",low_memory=False,)\n",
        "carrier_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/RUHealthHack/DE1_0_2008_to_2010_Carrier_Claims_Sample_1A.csv\", low_memory=False)\n",
        "\n",
        "\n",
        "chronic_conditions = [\n",
        "    'SP_ALZHDMTA', 'SP_CHF', 'SP_CHRNKIDN', 'SP_CNCR', 'SP_COPD',\n",
        "    'SP_DEPRESSN', 'SP_DIABETES', 'SP_ISCHMCHT', 'SP_OSTEOPRS',\n",
        "    'SP_RA_OA', 'SP_STRKETIA'\n",
        "]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jd0RQ-3fDexa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate inpatient and outpatient claims with unique IDs\n",
        "claims_data = pd.concat([inpatient_df[['DESYNPUF_ID', 'CLM_ID', 'CLM_PMT_AMT', 'CLM_FROM_DT']],\n",
        "                         outpatient_df[['DESYNPUF_ID', 'CLM_ID', 'CLM_PMT_AMT', 'CLM_FROM_DT']]])\n",
        "claims_data['CLM_FROM_DT'] = pd.to_datetime(claims_data['CLM_FROM_DT'])\n",
        "\n",
        "# Merge chronic conditions with claims data\n",
        "claims_data = claims_data.merge(beneficiary_df[['DESYNPUF_ID'] + chronic_conditions], on='DESYNPUF_ID', how='left')\n",
        "\n",
        "\n",
        "numeric_features = ['CLM_PMT_AMT']\n"
      ],
      "metadata": {
        "id": "Jne5QjqQEjvK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling numeric features\n",
        "scaler = StandardScaler()\n",
        "claims_data[numeric_features] = scaler.fit_transform(claims_data[numeric_features])\n",
        "\n",
        "# Combine binary chronic conditions with scaled numeric features\n",
        "X = claims_data[chronic_conditions + numeric_features].values\n",
        "\n",
        "# Step 2: Split Data for Training and Testing\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to torch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "wVzLfBkmDiDR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "R38ozRC15Zzb",
        "outputId": "55d0f9c1-c688-4834-d839-58132380dee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 1.4518\n",
            "Epoch [20/50], Loss: 1.3413\n",
            "Epoch [30/50], Loss: 1.0840\n",
            "Epoch [40/50], Loss: 0.7707\n",
            "Epoch [50/50], Loss: 0.6683\n",
            "Total Test Samples: 171513\n",
            "Detected Outliers: 1418\n",
            "\n",
            "Detected Outlier Samples:\n",
            "   SP_ALZHDMTA  SP_CHF  SP_CHRNKIDN  SP_CNCR  SP_COPD  SP_DEPRESSN  \\\n",
            "0          1.0     1.0          2.0      2.0      1.0          2.0   \n",
            "1          1.0     1.0          1.0      2.0      1.0          2.0   \n",
            "2          2.0     2.0          1.0      2.0      2.0          1.0   \n",
            "3          2.0     1.0          1.0      2.0      1.0          1.0   \n",
            "4          2.0     1.0          1.0      2.0      1.0          1.0   \n",
            "\n",
            "   SP_DIABETES  SP_ISCHMCHT  SP_OSTEOPRS  SP_RA_OA  SP_STRKETIA  CLM_PMT_AMT  \n",
            "0          1.0          2.0          2.0       2.0          2.0    10.436005  \n",
            "1          1.0          1.0          2.0       2.0          2.0     4.942322  \n",
            "2          2.0          1.0          2.0       2.0          2.0    12.908162  \n",
            "3          1.0          1.0          1.0       2.0          2.0    15.380320  \n",
            "4          1.0          1.0          2.0       2.0          2.0    15.380320  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-299c97ca3f5f>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Example usage with a sample new entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0msample_entry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Replace with actual new data if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mis_outlier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_new_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_entry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchronic_conditions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nSample Entry Reconstruction Error: {error:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "# Step 3: Define the Autoencoder Model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "model = Autoencoder(input_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 4: Train the Autoencoder\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, X_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Step 5: Evaluate Model and Calculate Reconstruction Error for Outlier Detection\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Calculate reconstruction error on test set\n",
        "    reconstructions = model(X_test_tensor)\n",
        "    reconstruction_errors = torch.mean((reconstructions - X_test_tensor) ** 2, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "version = \"v1.0\"\n",
        "\n",
        "# Create a timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Model file name based on timestamp, version, and \"outlier\" keyword\n",
        "model_filename = f\"/content/drive/MyDrive/Colab Notebooks/RUHealthHack/models/outlier_model_{version}_{timestamp}.pth\"\n",
        "torch.save(model.state_dict(), model_filename)\n",
        "print(f\"Model saved to {model_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MfN2rx3IhCa",
        "outputId": "ec185dd8-5914-4359-f215-d503ed5a2ead"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/Colab Notebooks/RUHealthHack/models/outlier_model_v1.0_20241026_232314.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Determine Outlier Thresholds\n",
        "# Set threshold dynamically (e.g., mean + 2 standard deviations of reconstruction errors)\n",
        "threshold = reconstruction_errors.mean() + 2 * reconstruction_errors.std()\n",
        "\n",
        "# Identify outliers based on reconstruction error\n",
        "outliers = reconstruction_errors > threshold\n",
        "\n",
        "# Display outlier detection results\n",
        "print(f\"Total Test Samples: {len(X_test)}\")\n",
        "print(f\"Detected Outliers: {outliers.sum().item()}\")\n",
        "\n",
        "# Step 7: Detailed Analysis of Outliers\n",
        "# Extract outliers for further inspection\n",
        "outlier_indices = np.where(outliers)[0]\n",
        "outlier_data = pd.DataFrame(X_test[outlier_indices], columns=chronic_conditions + numeric_features)\n",
        "\n",
        "print(\"\\nDetected Outlier Samples:\")\n",
        "print(outlier_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vnSp6_oFtYv",
        "outputId": "9cb1a37b-6e8a-4b30-b1fe-5e9659a60274"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Test Samples: 171513\n",
            "Detected Outliers: 1418\n",
            "\n",
            "Detected Outlier Samples:\n",
            "   SP_ALZHDMTA  SP_CHF  SP_CHRNKIDN  SP_CNCR  SP_COPD  SP_DEPRESSN  \\\n",
            "0          1.0     1.0          2.0      2.0      1.0          2.0   \n",
            "1          1.0     1.0          1.0      2.0      1.0          2.0   \n",
            "2          2.0     2.0          1.0      2.0      2.0          1.0   \n",
            "3          2.0     1.0          1.0      2.0      1.0          1.0   \n",
            "4          2.0     1.0          1.0      2.0      1.0          1.0   \n",
            "\n",
            "   SP_DIABETES  SP_ISCHMCHT  SP_OSTEOPRS  SP_RA_OA  SP_STRKETIA  CLM_PMT_AMT  \n",
            "0          1.0          2.0          2.0       2.0          2.0    10.436005  \n",
            "1          1.0          1.0          2.0       2.0          2.0     4.942322  \n",
            "2          2.0          1.0          2.0       2.0          2.0    12.908162  \n",
            "3          1.0          1.0          1.0       2.0          2.0    15.380320  \n",
            "4          1.0          1.0          2.0       2.0          2.0    15.380320  \n"
          ]
        }
      ]
    }
  ]
}